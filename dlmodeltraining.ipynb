{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12771533,"sourceType":"datasetVersion","datasetId":8073899}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"8c024913","cell_type":"markdown","source":"# U-Net++ Change Detection Training Notebook\nThis notebook trains a U-Net++ model for change detection using A/B/label folders for train, val, and test. It includes installation, data loading, training with early stopping, saving metrics, and displaying results.","metadata":{}},{"id":"e4186f53","cell_type":"markdown","source":"## Assignment Compliance (Segmentation)\n- Problem: Change detection (binary segmentation of change mask)\n- Model: U-Net++ (recent variant, deeper variant over base U-Net)\n- Epochs: Min 50 with early stopping (patience 10)\n- Data: Using existing train / val / test folders exactly as provided (no re-splitting enforced).\n- Metrics tracked: IoU, Dice, Precision, Recall, F1, Accuracy, Loss + confusion matrix (pixel-wise)\n- Outputs: Metric plots, sample predictions, parameter count, GFLOPs, saved best weights.\n- Saved artifacts: best_model.pth, training_history.csv, test_metrics.csv, confusion_matrix.txt, prediction PNGs.\n","metadata":{}},{"id":"602e44af","cell_type":"code","source":"# Install all required packages\n!pip install segmentation-models-pytorch torch torchvision albumentations scikit-learn pandas tqdm thop torchinfo matplotlib seaborn --quiet","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"c9d4579f","cell_type":"code","source":"# Imports & Setup for custom U-Net++ training (from scratch style like Siamese notebook)\nimport os, random, math\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom tqdm import tqdm\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Device & Reproducibility\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed_all(SEED)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\nprint(f\"Using device: {DEVICE}\")\n\n# Loss components (Dice + BCE)\nclass DiceLoss(nn.Module):\n    def __init__(self, smooth=1e-6):\n        super().__init__()\n        self.smooth = smooth\n    def forward(self, preds, targets):\n        # preds: probabilities after sigmoid, targets: binary\n        preds = preds.contiguous()\n        targets = targets.contiguous()\n        intersection = (preds * targets).sum(dim=(2,3))\n        denom = preds.sum(dim=(2,3)) + targets.sum(dim=(2,3))\n        dice = (2 * intersection + self.smooth) / (denom + self.smooth)\n        return 1 - dice.mean()\n\ndef combined_loss(logits, targets, bce_w=0.6, dice_w=0.4):\n    bce = nn.BCEWithLogitsLoss()(logits, targets)\n    probs = torch.sigmoid(logits)\n    dloss = DiceLoss()(probs, targets)\n    return bce_w * bce + dice_w * dloss\n\n@torch.no_grad()\ndef batch_metrics(logits, targets, thresh=0.5):\n    probs = torch.sigmoid(logits)\n    preds = (probs >= thresh).float()\n    p = preds.view(-1).cpu().numpy()\n    t = targets.view(-1).cpu().numpy()\n    # Confusion components\n    cm = confusion_matrix(t, p, labels=[0,1]) if (t.sum()>0 or p.sum()>0) else np.array([[len(t),0],[0,0]])\n    if cm.shape == (2,2):\n        tn, fp, fn, tp = cm.ravel()\n    else:  # degenerate\n        tn = fp = fn = tp = 0\n    eps = 1e-8\n    iou = tp / (tp + fp + fn + eps)\n    dice = (2*tp) / (2*tp + fp + fn + eps)\n    precision = tp / (tp + fp + eps) if (tp+fp)>0 else 0.0\n    recall = tp / (tp + fn + eps) if (tp+fn)>0 else 0.0\n    f1 = 2*precision*recall/(precision+recall+eps) if (precision+recall)>0 else 0.0\n    acc = (tp + tn) / (tp + tn + fp + fn + eps)\n    return dict(tp=int(tp), fp=int(fp), fn=int(fn), tn=int(tn), iou=float(iou), dice=float(dice), precision=float(precision), recall=float(recall), f1=float(f1), acc=float(acc))\n\nclass EarlyStopping:\n    def __init__(self, patience=15, min_delta=1e-4, restore_best=True, min_epochs=50):\n        self.patience = patience\n        self.min_delta = min_delta\n        self.restore_best = restore_best\n        self.best_loss = None\n        self.counter = 0\n        self.best_state = None\n        self.min_epochs = min_epochs\n    def __call__(self, epoch, current_loss, model):\n        if self.best_loss is None or (self.best_loss - current_loss) > self.min_delta:\n            self.best_loss = current_loss\n            self.counter = 0\n            if self.restore_best:\n                self.best_state = {k: v.detach().cpu().clone() for k,v in model.state_dict().items()}\n        else:\n            self.counter += 1\n        if epoch+1 < self.min_epochs:\n            return False\n        if self.counter >= self.patience:\n            if self.restore_best and self.best_state is not None:\n                model.load_state_dict(self.best_state)\n            return True\n        return False","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"1713601c","cell_type":"code","source":"# Dataset (from scratch style, similar to Siamese approach)\nDATA_ROOT = '/kaggle/input/earthquakedatasetnew/earthquakeDataset'  # Adjust to local path as needed\nIMG_SIZE = (256, 256)\nTRAIN_BATCH = 4\nVAL_BATCH = 2\nTEST_BATCH = 1\n\ntransform_img = transforms.Compose([\n    transforms.Resize(IMG_SIZE),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n])\ntransform_mask = transforms.Compose([\n    transforms.Resize(IMG_SIZE),\n    transforms.ToTensor()\n])\n\nclass ChangeDataset(Dataset):\n    def __init__(self, root, split='train'):\n        if split=='train':\n            a_dir = os.path.join(root,'train','A_train_aug')\n            b_dir = os.path.join(root,'train','B_train_aug')\n            m_dir = os.path.join(root,'train','label_train_aug')\n        elif split=='val':\n            a_dir = os.path.join(root,'val','A_val')\n            b_dir = os.path.join(root,'val','B_val')\n            m_dir = os.path.join(root,'val','label_val')\n        else:\n            a_dir = os.path.join(root,'test','A_test')\n            b_dir = os.path.join(root,'test','B_test')\n            m_dir = os.path.join(root,'test','label_test')\n        self.a_files = sorted([f for f in os.listdir(a_dir) if f.endswith('.png')])\n        self.a_dir, self.b_dir, self.m_dir = a_dir, b_dir, m_dir\n    def __len__(self): return len(self.a_files)\n    def __getitem__(self, idx):\n        name = self.a_files[idx]\n        a = Image.open(os.path.join(self.a_dir,name)).convert('RGB')\n        b = Image.open(os.path.join(self.b_dir,name)).convert('RGB')\n        m = Image.open(os.path.join(self.m_dir,name)).convert('L')\n        a = transform_img(a)\n        b = transform_img(b)\n        m = transform_mask(m)\n        m = (m>0.5).float()\n        x = torch.cat([a,b], dim=0)  # 6 channels\n        return x, m\n\ntrain_ds = ChangeDataset(DATA_ROOT,'train')\nval_ds = ChangeDataset(DATA_ROOT,'val')\ntest_ds = ChangeDataset(DATA_ROOT,'test')\n\ntrain_loader = DataLoader(train_ds, batch_size=TRAIN_BATCH, shuffle=True, num_workers=2, pin_memory=True)\nval_loader = DataLoader(val_ds, batch_size=VAL_BATCH, shuffle=False, num_workers=1)\ntest_loader = DataLoader(test_ds, batch_size=TEST_BATCH, shuffle=False, num_workers=1)\n\nprint(f\"Train {len(train_ds)} | Val {len(val_ds)} | Test {len(test_ds)}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"4c606b92","cell_type":"code","source":"# Custom U-Net++ (Nested U-Net) implementation\nclass ConvBlock(nn.Module):\n    def __init__(self, in_ch, out_ch):\n        super().__init__()\n        self.block = nn.Sequential(\n            nn.Conv2d(in_ch, out_ch, 3, padding=1, bias=False),\n            nn.BatchNorm2d(out_ch),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(out_ch, out_ch, 3, padding=1, bias=False),\n            nn.BatchNorm2d(out_ch),\n            nn.ReLU(inplace=True)\n        )\n    def forward(self,x): return self.block(x)\n\nclass UNetPP(nn.Module):\n    def __init__(self, in_ch=6, out_ch=1, filters=(32,64,128,256,512), deep_supervision=False):\n        super().__init__()\n        self.deep_supervision = deep_supervision\n        f = filters\n        # Encoder base layers (x_0_0 .. x_4_0)\n        self.x_0_0 = ConvBlock(in_ch, f[0])\n        self.x_1_0 = ConvBlock(f[0], f[1])\n        self.x_2_0 = ConvBlock(f[1], f[2])\n        self.x_3_0 = ConvBlock(f[2], f[3])\n        self.x_4_0 = ConvBlock(f[3], f[4])\n        self.pool = nn.MaxPool2d(2)\n        self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n        # Nested decoder blocks (dense skip connections)\n        self.x_0_1 = ConvBlock(f[0]+f[1], f[0])\n        self.x_1_1 = ConvBlock(f[1]+f[2], f[1])\n        self.x_2_1 = ConvBlock(f[2]+f[3], f[2])\n        self.x_3_1 = ConvBlock(f[3]+f[4], f[3])\n\n        self.x_0_2 = ConvBlock(f[0]*2+f[1], f[0])\n        self.x_1_2 = ConvBlock(f[1]*2+f[2], f[1])\n        self.x_2_2 = ConvBlock(f[2]*2+f[3], f[2])\n\n        self.x_0_3 = ConvBlock(f[0]*3+f[1], f[0])\n        self.x_1_3 = ConvBlock(f[1]*3+f[2], f[1])\n\n        self.x_0_4 = ConvBlock(f[0]*4+f[1], f[0])\n\n        self.final = nn.Conv2d(f[0], out_ch, 1)\n    def forward(self,x):\n        x_0_0 = self.x_0_0(x)\n        x_1_0 = self.x_1_0(self.pool(x_0_0))\n        x_0_1 = self.x_0_1(torch.cat([x_0_0, self.up(x_1_0)], dim=1))\n\n        x_2_0 = self.x_2_0(self.pool(x_1_0))\n        x_1_1 = self.x_1_1(torch.cat([x_1_0, self.up(x_2_0)], dim=1))\n        x_0_2 = self.x_0_2(torch.cat([x_0_0, x_0_1, self.up(x_1_1)], dim=1))\n\n        x_3_0 = self.x_3_0(self.pool(x_2_0))\n        x_2_1 = self.x_2_1(torch.cat([x_2_0, self.up(x_3_0)], dim=1))\n        x_1_2 = self.x_1_2(torch.cat([x_1_0, x_1_1, self.up(x_2_1)], dim=1))\n        x_0_3 = self.x_0_3(torch.cat([x_0_0, x_0_1, x_0_2, self.up(x_1_2)], dim=1))\n\n        x_4_0 = self.x_4_0(self.pool(x_3_0))\n        x_3_1 = self.x_3_1(torch.cat([x_3_0, self.up(x_4_0)], dim=1))\n        x_2_2 = self.x_2_2(torch.cat([x_2_0, x_2_1, self.up(x_3_1)], dim=1))\n        x_1_3 = self.x_1_3(torch.cat([x_1_0, x_1_1, x_1_2, self.up(x_2_2)], dim=1))\n        x_0_4 = self.x_0_4(torch.cat([x_0_0, x_0_1, x_0_2, x_0_3, self.up(x_1_3)], dim=1))\n\n        out = self.final(x_0_4)\n        return out\n\n# Instantiate model & optimizer\nmodel = UNetPP(in_ch=6, out_ch=1, filters=(32,64,128,256,512)).to(DEVICE)\nprint(f\"Model params: {sum(p.numel() for p in model.parameters()):,}\")\n\noptimizer = torch.optim.AdamW(model.parameters(), lr=2e-4, weight_decay=1e-3)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.7, patience=7, verbose=True, min_lr=1e-6)\nearly_stop = EarlyStopping(patience=10, min_delta=1e-4, min_epochs=50)\n\nEPOCHS = 200\nhistory = []\n\nfor epoch in range(EPOCHS):\n    model.train()\n    train_loss = 0.0\n    for xb, yb in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} Train\", leave=False):\n        xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n        optimizer.zero_grad()\n        logits = model(xb)\n        loss = combined_loss(logits, yb)\n        loss.backward()\n        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        optimizer.step()\n        train_loss += loss.item() * xb.size(0)\n    train_loss /= len(train_loader.dataset)\n\n    # Validation\n    model.eval()\n    val_loss = 0.0\n    agg = dict(tp=0,fp=0,fn=0,tn=0)\n    with torch.no_grad():\n        for xb, yb in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} Val\", leave=False):\n            xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n            logits = model(xb)\n            loss = combined_loss(logits, yb)\n            val_loss += loss.item() * xb.size(0)\n            mets = batch_metrics(logits, yb)\n            for k in agg: agg[k] += mets[k]\n    val_loss /= len(val_loader.dataset)\n    eps=1e-8\n    tp,fp,fn,tn = agg['tp'],agg['fp'],agg['fn'],agg['tn']\n    iou = tp / (tp+fp+fn+eps)\n    dice = (2*tp)/(2*tp+fp+fn+eps)\n    precision = tp/(tp+fp+eps) if (tp+fp)>0 else 0\n    recall = tp/(tp+fn+eps) if (tp+fn)>0 else 0\n    f1 = 2*precision*recall/(precision+recall+eps) if (precision+recall)>0 else 0\n    acc = (tp+tn)/(tp+tn+fp+fn+eps)\n    history.append(dict(epoch=epoch+1, train_loss=train_loss, val_loss=val_loss, IoU=iou, Dice=dice, Precision=precision, Recall=recall, F1=f1, Accuracy=acc))\n\n    scheduler.step(val_loss)\n    print(f\"Epoch {epoch+1}: TL {train_loss:.4f} VL {val_loss:.4f} IoU {iou:.4f} Dice {dice:.4f} F1 {f1:.4f} LR {optimizer.param_groups[0]['lr']:.2e}\")\n\n    # Save best\n    if epoch==0 or val_loss == min(h['val_loss'] for h in history):\n        torch.save(model.state_dict(), 'best_unetpp_custom.pth')\n\n    if early_stop(epoch, val_loss, model):\n        print(f\"Early stopping at epoch {epoch+1}\")\n        break\n\n# Save training history\npd.DataFrame(history).to_csv('training_history_unetpp.csv', index=False)\nprint('Training complete.')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"e415ee87","cell_type":"code","source":"# Test evaluation for custom U-Net++\nmodel = UNetPP(in_ch=6, out_ch=1, filters=(32,64,128,256,512)).to(DEVICE)\nmodel.load_state_dict(torch.load('best_unetpp_custom.pth', map_location=DEVICE))\nmodel.eval()\n\nagg = dict(tp=0,fp=0,fn=0,tn=0)\nall_preds = []\nwith torch.no_grad():\n    for xb, yb in tqdm(test_loader, desc=\"Test\", leave=False):\n        xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n        logits = model(xb)\n        mets = batch_metrics(logits, yb)\n        for k in agg: agg[k] += mets[k]\n        probs = torch.sigmoid(logits)\n        preds = (probs>=0.5).float().cpu()\n        all_preds.append(preds)\n\nall_preds = torch.cat(all_preds, dim=0)\n\neps=1e-8\ntp,fp,fn,tn = agg['tp'],agg['fp'],agg['fn'],agg['tn']\niou = tp/(tp+fp+fn+eps)\ndice = (2*tp)/(2*tp+fp+fn+eps)\nprecision = tp/(tp+fp+eps) if (tp+fp)>0 else 0\nrecall = tp/(tp+fn+eps) if (tp+fn)>0 else 0\nf1 = 2*precision*recall/(precision+recall+eps) if (precision+recall)>0 else 0\nacc = (tp+tn)/(tp+tn+fp+fn+eps)\ncm = np.array([[tn, fp],[fn, tp]])\nmetrics = dict(IoU=iou, Dice=dice, Precision=precision, Recall=recall, F1=f1, Accuracy=acc, TP=tp, FP=fp, FN=fn, TN=tn)\nprint('Confusion Matrix:\\n', cm)\nprint('Test Metrics:', metrics)\n\npd.DataFrame([metrics]).to_csv('test_metrics_unetpp.csv', index=False)\nnp.savetxt('confusion_matrix_unetpp.txt', cm, fmt='%d')\n\n# Save first 10 prediction masks\nos.makedirs('test_predictions_unetpp', exist_ok=True)\nfor i in range(min(10, all_preds.shape[0])):\n    img = (all_preds[i,0].numpy()*255).astype('uint8')\n    Image.fromarray(img).save(f'test_predictions_unetpp/pred_{i}.png')\nprint('Saved prediction samples.')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"416e3172","cell_type":"code","source":"# Visualization for custom U-Net++ results\nhist_df = pd.read_csv('training_history_unetpp.csv')\nprint('History head:')\nprint(hist_df.head())\n\nfig, ((ax1, ax2, ax3),(ax4, ax5, ax6)) = plt.subplots(2,3, figsize=(16,8))\nax1.plot(hist_df['epoch'], hist_df['train_loss'], label='Train Loss')\nax1.plot(hist_df['epoch'], hist_df['val_loss'], label='Val Loss')\nax1.set_title('Loss'); ax1.legend()\nax2.plot(hist_df['epoch'], hist_df['IoU'], label='IoU', color='green')\nax2.set_title('Validation IoU')\nax3.plot(hist_df['epoch'], hist_df['Dice'], label='Dice', color='orange')\nax3.set_title('Validation Dice')\nax4.plot(hist_df['epoch'], hist_df['Precision'], label='Precision')\nax4.plot(hist_df['epoch'], hist_df['Recall'], label='Recall')\nax4.set_title('Precision & Recall'); ax4.legend()\nax5.plot(hist_df['epoch'], hist_df['F1'], label='F1')\nax5.plot(hist_df['epoch'], hist_df['Accuracy'], label='Accuracy')\nax5.set_title('F1 & Accuracy'); ax5.legend()\nax6.axis('off')\nplt.tight_layout(); plt.show()\n\n# Load test metrics\nmetrics_df = pd.read_csv('test_metrics_unetpp.csv')\nprint('Test Metrics:')\nprint(metrics_df.T)\n\n# Confusion matrix heatmap\ncm = np.loadtxt('confusion_matrix_unetpp.txt', dtype=int)\nplt.figure(figsize=(4,4))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\nplt.title('Pixel Confusion Matrix')\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.show()\n\n# Show sample predictions\nfor i in range(3):\n    p_path = f'test_predictions_unetpp/pred_{i}.png'\n    if os.path.exists(p_path):\n        plt.figure()\n        plt.imshow(Image.open(p_path), cmap='gray')\n        plt.title(f'Pred {i}')\n        plt.axis('off')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}