{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c024913",
   "metadata": {},
   "source": [
    "# U-Net++ Change Detection Training Notebook\n",
    "This notebook trains a U-Net++ model for change detection using A/B/label folders for train, val, and test. It includes installation, data loading, training with early stopping, saving metrics, and displaying results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4186f53",
   "metadata": {},
   "source": [
    "## Assignment Compliance (Segmentation)\n",
    "- Problem: Change detection (binary segmentation of change mask)\n",
    "- Model: U-Net++ (recent variant, deeper variant over base U-Net)\n",
    "- Epochs: Min 50 with early stopping (patience 10)\n",
    "- Data: Using existing train / val / test folders exactly as provided (no re-splitting enforced).\n",
    "- Metrics tracked: IoU, Dice, Precision, Recall, F1, Accuracy, Loss + confusion matrix (pixel-wise)\n",
    "- Outputs: Metric plots, sample predictions, parameter count, GFLOPs, saved best weights.\n",
    "- Saved artifacts: best_model.pth, training_history.csv, test_metrics.csv, confusion_matrix.txt, prediction PNGs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602e44af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install all required packages\n",
    "!pip install segmentation-models-pytorch torch torchvision albumentations scikit-learn pandas tqdm thop torchinfo matplotlib seaborn --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d4579f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import segmentation_models_pytorch as smp\n",
    "from sklearn.metrics import f1_score, accuracy_score, jaccard_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1713601c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loading and Dataset Definition\n",
    "DATA_ROOT = '/kaggle/input/your-dataset-folder'  # Change to your dataset path\n",
    "TRAIN_DIR = os.path.join(DATA_ROOT, 'train')\n",
    "VAL_DIR = os.path.join(DATA_ROOT, 'val')\n",
    "TEST_DIR = os.path.join(DATA_ROOT, 'test')\n",
    "\n",
    "A_TRAIN = os.path.join(TRAIN_DIR, 'A_train_aug')\n",
    "B_TRAIN = os.path.join(TRAIN_DIR, 'B_train_aug')\n",
    "LABEL_TRAIN = os.path.join(TRAIN_DIR, 'label_train_aug')\n",
    "\n",
    "A_VAL = os.path.join(VAL_DIR, 'A_val')\n",
    "B_VAL = os.path.join(VAL_DIR, 'B_val')\n",
    "LABEL_VAL = os.path.join(VAL_DIR, 'label_val')\n",
    "\n",
    "A_TEST = os.path.join(TEST_DIR, 'A_test')\n",
    "B_TEST = os.path.join(TEST_DIR, 'B_test')\n",
    "LABEL_TEST = os.path.join(TEST_DIR, 'label_test')\n",
    "\n",
    "IMG_SIZE = (256, 256)\n",
    "BATCH_SIZE = 16\n",
    "MIN_EPOCHS = 100\n",
    "PATIENCE = 10\n",
    "\n",
    "class ChangeDataset(Dataset):\n",
    "    def __init__(self, a_dir, b_dir, label_dir):\n",
    "        self.a_files = sorted([os.path.join(a_dir, f) for f in os.listdir(a_dir) if f.endswith('.png')])\n",
    "        self.b_files = sorted([os.path.join(b_dir, f) for f in os.listdir(b_dir) if f.endswith('.png')])\n",
    "        self.label_files = sorted([os.path.join(label_dir, f) for f in os.listdir(label_dir) if f.endswith('.png')])\n",
    "        assert len(self.a_files) == len(self.b_files) == len(self.label_files)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.a_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        a_img = np.array(Image.open(self.a_files[idx]).convert('RGB')).astype('float32') / 255.0\n",
    "        b_img = np.array(Image.open(self.b_files[idx]).convert('RGB')).astype('float32') / 255.0\n",
    "        label = np.array(Image.open(self.label_files[idx]).convert('L')).astype('float32') / 255.0\n",
    "        label = (label > 0.5).astype('float32')\n",
    "        x = np.concatenate([a_img, b_img], axis=2)\n",
    "        x = np.transpose(x, (2, 0, 1))\n",
    "        y = label[np.newaxis, ...]\n",
    "        return torch.tensor(x), torch.tensor(y)\n",
    "\n",
    "train_ds = ChangeDataset(A_TRAIN, B_TRAIN, LABEL_TRAIN)\n",
    "val_ds = ChangeDataset(A_VAL, B_VAL, LABEL_VAL)\n",
    "test_ds = ChangeDataset(A_TEST, B_TEST, LABEL_TEST)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c606b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Setup and Training Loop with extended metrics\n",
    "model = smp.UnetPlusPlus(\n",
    "    encoder_name='resnet34',\n",
    "    in_channels=6,\n",
    "    classes=1,\n",
    "    activation=None\n",
    ").cuda()\n",
    "\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "def compute_seg_metrics(y_true, y_pred):\n",
    "    # y_true, y_pred: (N,1,H,W) float tensors\n",
    "    y_true = y_true.detach().cpu().numpy().astype('uint8')\n",
    "    y_pred = (y_pred.detach().cpu().numpy() > 0.5).astype('uint8')\n",
    "    flat_t = y_true.reshape(-1)\n",
    "    flat_p = y_pred.reshape(-1)\n",
    "    intersection = (flat_t & flat_p).sum()\n",
    "    union = (flat_t | flat_p).sum() + 1e-7\n",
    "    iou = intersection / union\n",
    "    dice = (2*intersection) / (flat_t.sum() + flat_p.sum() + 1e-7)\n",
    "    prec = precision_score(flat_t, flat_p, zero_division=0)\n",
    "    rec = recall_score(flat_t, flat_p, zero_division=0)\n",
    "    f1 = f1_score(flat_t, flat_p, zero_division=0)\n",
    "    acc = (flat_t == flat_p).mean()\n",
    "    return dict(IoU=iou, Dice=dice, Precision=prec, Recall=rec, F1=f1, Accuracy=acc)\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "history = []\n",
    "for epoch in range(1, 1000):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for x, y in train_loader:\n",
    "        x, y = x.cuda(), y.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x)\n",
    "        loss = loss_fn(out, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * x.size(0)\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_preds = []\n",
    "    val_trues = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "            out = model(x)\n",
    "            loss = loss_fn(out, y)\n",
    "            val_loss += loss.item() * x.size(0)\n",
    "            val_preds.append(torch.sigmoid(out))\n",
    "            val_trues.append(y)\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "\n",
    "    # Metrics on concatenated tensors\n",
    "    val_preds_cat = torch.cat(val_preds, dim=0)\n",
    "    val_trues_cat = torch.cat(val_trues, dim=0)\n",
    "    metrics = compute_seg_metrics(val_trues_cat, val_preds_cat)\n",
    "    history.append({'epoch':epoch,'train_loss':train_loss,'val_loss':val_loss, **metrics})\n",
    "\n",
    "    print(f\"Epoch {epoch}: TL {train_loss:.4f} VL {val_loss:.4f} IoU {metrics['IoU']:.4f} Dice {metrics['Dice']:.4f} F1 {metrics['F1']:.4f}\")\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        epochs_no_improve = 0\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "\n",
    "    if epoch >= 50 and epochs_no_improve >= 10:\n",
    "        print(f'Early stopping at epoch {epoch}')\n",
    "        break\n",
    "\n",
    "import pandas as pd\n",
    "hist_df = pd.DataFrame(history)\n",
    "hist_df.to_csv('training_history.csv', index=False)\n",
    "print('Training complete. Best val loss:', best_val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e415ee87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Best Model and Evaluate on Test Set with full metrics\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "from torchinfo import summary\n",
    "from thop import profile\n",
    "\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "# Parameter count & GFLOPs\n",
    "sample_input = torch.randn(1,6,256,256).cuda()\n",
    "macs, params = profile(model, inputs=(sample_input,), verbose=False)\n",
    "GFLOPs = macs/1e9\n",
    "param_millions = params/1e6\n",
    "print(f'GFLOPs: {GFLOPs:.3f}, Params (M): {param_millions:.3f}')\n",
    "\n",
    "all_preds = []\n",
    "all_logits = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader:\n",
    "        x = x.cuda(); y = y.cuda()\n",
    "        out = model(x)\n",
    "        probs = torch.sigmoid(out)\n",
    "        preds = (probs > 0.5).float()\n",
    "        all_preds.append(preds.cpu())\n",
    "        all_logits.append(probs.cpu())\n",
    "        all_labels.append(y.cpu())\n",
    "\n",
    "all_preds = torch.cat(all_preds, dim=0)\n",
    "all_labels = torch.cat(all_labels, dim=0)\n",
    "\n",
    "# Metrics\n",
    "flat_p = all_preds.numpy().reshape(-1).astype('uint8')\n",
    "flat_t = all_labels.numpy().reshape(-1).astype('uint8')\n",
    "intersection = (flat_p & flat_t).sum()\n",
    "union = (flat_p | flat_t).sum() + 1e-7\n",
    "iou = intersection/union\n",
    "dice = (2*intersection)/(flat_p.sum()+flat_t.sum()+1e-7)\n",
    "prec = precision_score(flat_t, flat_p, zero_division=0)\n",
    "rec = recall_score(flat_t, flat_p, zero_division=0)\n",
    "f1 = f1_score(flat_t, flat_p, zero_division=0)\n",
    "acc = (flat_p==flat_t).mean()\n",
    "cm = confusion_matrix(flat_t, flat_p).astype(int)\n",
    "print('Confusion Matrix:\\n', cm)\n",
    "metrics = {'IoU':iou,'Dice':dice,'Precision':prec,'Recall':rec,'F1':f1,'Accuracy':acc,'GFLOPs':GFLOPs,'Params_M':param_millions}\n",
    "print('Test Metrics:', metrics)\n",
    "\n",
    "pd.DataFrame([metrics]).to_csv('test_metrics.csv', index=False)\n",
    "np.savetxt('confusion_matrix.txt', cm, fmt='%d')\n",
    "\n",
    "# Save predictions as images (first 10)\n",
    "import os\n",
    "os.makedirs('test_predictions', exist_ok=True)\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "for i in range(min(10, all_preds.shape[0])):\n",
    "    pred_img = (all_preds[i,0].numpy()*255).astype('uint8')\n",
    "    Image.fromarray(pred_img).save(f'test_predictions/pred_{i}.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416e3172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Final Results & Plots\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "hist_df = pd.read_csv('training_history.csv')\n",
    "print('History head:')\n",
    "print(hist_df.head())\n",
    "\n",
    "fig, axes = plt.subplots(2,3, figsize=(16,8))\n",
    "axes = axes.ravel()\n",
    "plot_cols = ['train_loss','val_loss','IoU','Dice','Precision','Recall']\n",
    "for ax,col in zip(axes, plot_cols):\n",
    "    ax.plot(hist_df['epoch'], hist_df[col], label=col)\n",
    "    ax.set_title(col)\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# F1 & Accuracy separate\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(hist_df['epoch'], hist_df['F1'], label='F1')\n",
    "plt.plot(hist_df['epoch'], hist_df['Accuracy'], label='Accuracy')\n",
    "plt.legend(); plt.title('F1 & Accuracy'); plt.xlabel('Epoch'); plt.show()\n",
    "\n",
    "# Load test metrics\n",
    "metrics_df = pd.read_csv('test_metrics.csv')\n",
    "print('Test Metrics:')\n",
    "print(metrics_df)\n",
    "\n",
    "# Confusion matrix heatmap\n",
    "import numpy as np\n",
    "cm = np.loadtxt('confusion_matrix.txt', dtype=int)\n",
    "plt.figure(figsize=(4,4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Pixel Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n",
    "\n",
    "# Show sample predictions\n",
    "import os\n",
    "from PIL import Image\n",
    "for i in range(3):\n",
    "    p_path = f'test_predictions/pred_{i}.png'\n",
    "    if os.path.exists(p_path):\n",
    "        plt.figure()\n",
    "        plt.imshow(Image.open(p_path), cmap='gray')\n",
    "        plt.title(f'Pred {i}')\n",
    "        plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
